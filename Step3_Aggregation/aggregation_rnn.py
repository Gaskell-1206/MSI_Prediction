# -*- coding: utf-8 -*-
"""Aggregation_RNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wRIWG9ltV88FPyolXPoVd7QDlaXE9PyX
"""

import sys
import os
import numpy as np
import pandas as pd
import argparse
import random
#import openslide
import PIL.Image as Image
import torch
import torch.nn as nn
import torch.optim as optim
import torch.backends.cudnn as cudnn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as transforms
import torchvision.models as models
from pathlib import Path
# from skimage import io
from collections import OrderedDict

class Args: 
    root_dir = '/Users/gaskell/Dropbox/Mac/Desktop/CBH/ex_data/CRC_DX_data_set/Dataset' 
    lib_file = '/Users/gaskell/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/dfdd17fe7ae83e1bd7aa612624ed99ce/Message/MessageTemp/c792df50cecdd184d70e6c6f5ca5b059/File/MIL_resnet18_bs64_lr1e-3_predictions-2.csv'
    output_path = '/Users/gaskell/Dropbox/Mac/Desktop/CBH/ex_data/CRC_DX_data_set/Output'
    model = '/content/drive/MyDrive/CRC_DX_data_set/Output/checkpoint_best.pth'
    batch_size = 1
    nepochs = 1
    num_workers = 1
    test_every = 1
    weights = 0.5
    topk = 1
    ndims = 256

def genPatientIdxDict(patient_ID):
    ''' generate patient->patches index dict
    '''
    patient_idx_dict = {}
    unique_patient, unique_patient_idx = np.unique(patient_ID, return_index=True)
    for p in unique_patient:
        patient_idx_dict[p] = np.where(patient_ID == p)[0]

    return patient_idx_dict, unique_patient_idx

def genTopkID(df,k):
  patient_idx_dict, unique_patient_idx = genPatientIdxDict(df['slides'])
  slide_id=[None]*len(unique_patient_idx)
  target=[None]*len(unique_patient_idx)
  tile_id=[None]*len(unique_patient_idx)
  for i in range(len(unique_patient_idx)):
        idx = patient_idx_dict[df['slides'][unique_patient_idx[i]]]
        probs = df['probability'][idx]
        idx = idx[np.argsort(probs)[-k:]]
        slide_id[i] = df['slides'][idx[0]]
        target[i] = df['target'][idx[0]]
        id = []
        for kk in range(k):
          id.append(df['tiles'][idx[kk]])
        tile_id[i] = id
  return slide_id, tile_id, target

best_acc = 0
def main():
    global args, best_acc
    args = Args()
    #args = parser.parse_args()

    # prepare topk tile_ids
    df = pd.read_csv(args.lib_file)
    slide_id, tile_id, target = genTopkID(df,1)
    lib = pd.DataFrame({'slides':slide_id, 'targets':target, 'grid':tile_id})
    
    #load libraries
    normalize = transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.1,0.1,0.1])
    trans = transforms.Compose([transforms.ToTensor(),normalize])
    train_dset = rnndata(lib, args.topk, args.root_dir, 'Test', transform=trans)
    train_loader = torch.utils.data.DataLoader(
        train_dset,
        batch_size=args.batch_size, shuffle=True,
        num_workers=args.num_workers, pin_memory=False)
    val_dset = rnndata(lib, args.topk, args.root_dir, 'Test', transform=trans)
    val_loader = torch.utils.data.DataLoader(
        val_dset,
        batch_size=args.batch_size, shuffle=False,
        num_workers=args.num_workers, pin_memory=False)

    #make model
    embedder = ResNetEncoder(args.model)
    for param in embedder.parameters():
        param.requires_grad = False
    embedder = embedder.cpu()
    embedder.eval()

    rnn = rnn_single(args.ndims)
    rnn = rnn.cpu()
    
    #optimization
    if args.weights==0.5:
        criterion = nn.CrossEntropyLoss().cpu()
    else:
        w = torch.Tensor([1-args.weights,args.weights])
        criterion = nn.CrossEntropyLoss(w).cpu()
    optimizer = optim.SGD(rnn.parameters(), 0.1, momentum=0.9, dampening=0, weight_decay=1e-4, nesterov=True)
    cudnn.benchmark = True

    fconv = open(os.path.join(args.output_path, 'convergence.csv'), 'w')
    fconv.write('epoch,train.loss,train.fpr,train.fnr,val.loss,val.fpr,val.fnr\n')
    fconv.close()

    #
    for epoch in range(args.nepochs):

        train_loss, train_fpr, train_fnr = train_single(epoch, embedder, rnn, train_loader, criterion, optimizer)
        val_loss, val_fpr, val_fnr = test_single(epoch, embedder, rnn, val_loader, criterion)

        fconv = open(os.path.join(args.output,'convergence.csv'), 'a')
        fconv.write('{},{},{},{},{},{},{}\n'.format(epoch+1, train_loss, train_fpr, train_fnr, val_loss, val_fpr, val_fnr))
        fconv.close()

        val_err = (val_fpr + val_fnr)/2
        if 1-val_err >= best_acc:
            best_acc = 1-val_err
            obj = {
                'epoch': epoch+1,
                'state_dict': rnn.state_dict()
            }
            torch.save(obj, os.path.join(args.output,'rnn_checkpoint_best.pth'))

class rnndata(Dataset):

    def __init__(self, lib, topk, root_dir, dataset_mode='Train', transform=None):

        self.s = topk
        self.transform = transform
        self.slidenames = lib['slides']
        self.targets = lib['targets']
        self.grid = lib['grid']
        #self.level = lib['level']
        #self.mult = lib['mult']
        self.mult = 1
        self.size = int(224*self.mult)
        #self.shuffle = shuffle
        self.root_dir = root_dir
        self.dset = f"CRC_DX_{dataset_mode}"

        slides = []
        for i, name in enumerate(lib['slides']):
            sys.stdout.write('Opening SVS headers: [{}/{}]\r'.format(i+1, len(lib['slides'])))
            sys.stdout.flush()
            slides.append(name)
        print('')
        self.slides = slides

    def __getitem__(self,index):

        slide = self.slidenames[index]
        grid = self.grid[index]
        #if self.shuffle:
        #    grid = random.sample(grid,len(grid))
        out = []
        label = 'CRC_DX_MSIMUT' if self.targets[index] == 1 else 'CRC_DX_MSS'
        for kk in range(self.s):
          img_name = "blk-{}-{}.png".format(grid[kk], slide)
          img_path = os.path.join(self.root_dir, self.dset, label, img_name)
          img = Image.open(img_path)

          if self.transform is not None:
            img = self.transform(img)
        out.append(img)
        
        return out, self.targets[index]

    def __len__(self):
        
        return len(self.targets)

class ResNetEncoder(nn.Module):

    def __init__(self, path):
        super(ResNetEncoder, self).__init__()

        temp = models.resnet34()
        temp.fc = nn.Linear(temp.fc.in_features, 2)
        # ch = torch.load(path)
        # temp.load_state_dict(ch['state_dict'])
        self.features = nn.Sequential(*list(temp.children())[:-1])
        self.fc = temp.fc

    def forward(self,x):
        x = self.features(x)
        x = x.view(x.size(0),-1)
        return self.fc(x), x

class rnn_single(nn.Module):

    def __init__(self, ndims):
        super(rnn_single, self).__init__()
        self.ndims = ndims

        self.fc1 = nn.Linear(512, ndims)
        self.fc2 = nn.Linear(ndims, ndims)

        self.fc3 = nn.Linear(ndims, 2)

        self.activation = nn.ReLU()

    def forward(self, input, state):
        input = self.fc1(input)
        state = self.fc2(state)
        state = self.activation(state+input)
        output = self.fc3(state)
        return output, state

    def init_hidden(self, batch_size):
        return torch.zeros(batch_size, self.ndims)

def train_single(epoch, embedder, rnn, loader, criterion, optimizer):
    rnn.train()
    running_loss = 0.
    running_fps = 0.
    running_fns = 0.

    for i,(inputs,target) in enumerate(loader):
        print('Training - Epoch: [{}/{}]\tBatch: [{}/{}]'.format(epoch+1, args.nepochs, i+1, len(loader)))

        batch_size = inputs[0].size(0)
        rnn.zero_grad()

        state = rnn.init_hidden(batch_size).cpu()
        for s in range(len(inputs)):
            input = inputs[s].cpu()
            _, input = embedder(input)
            output, state = rnn(input, state)

        target = target.cpu()
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()*target.size(0)
        fps, fns = errors(output.detach(), target.cpu())
        running_fps += fps
        running_fns += fns

    running_loss = running_loss/len(loader.dataset)
    running_fps = running_fps/(np.array(loader.dataset.targets)==0).sum()
    running_fns = running_fns/(np.array(loader.dataset.targets)==1).sum()
    print('Training - Epoch: [{}/{}]\tLoss: {}\tFPR: {}\tFNR: {}'.format(epoch+1, args.nepochs, running_loss, running_fps, running_fns))
    return running_loss, running_fps, running_fns

def test_single(epoch, embedder, rnn, loader, criterion):
    rnn.eval()
    running_loss = 0.
    running_fps = 0.
    running_fns = 0.

    with torch.no_grad():
        for i,(inputs,target) in enumerate(loader):
            print('Validating - Epoch: [{}/{}]\tBatch: [{}/{}]'.format(epoch+1,args.nepochs,i+1,len(loader)))
            
            batch_size = inputs[0].size(0)
            
            state = rnn.init_hidden(batch_size).cpu()
            for s in range(len(inputs)):
                input = inputs[s].cpu()
                _, input = embedder(input)
                output, state = rnn(input, state)
            
            target = target.cpu()
            loss = criterion(output,target)
            
            running_loss += loss.item()*target.size(0)
            fps, fns = errors(output.detach(), target.cpu())
            running_fps += fps
            running_fns += fns
            
    running_loss = running_loss/len(loader.dataset)
    running_fps = running_fps/(np.array(loader.dataset.targets)==0).sum()
    running_fns = running_fns/(np.array(loader.dataset.targets)==1).sum()
    print('Validating - Epoch: [{}/{}]\tLoss: {}\tFPR: {}\tFNR: {}'.format(epoch+1, args.nepochs, running_loss, running_fps, running_fns))
    return running_loss, running_fps, running_fns

def errors(output, target):
    _, pred = output.topk(1, 1, True, True)
    pred = pred.squeeze().cpu().numpy()
    real = target.numpy()
    neq = pred!=real
    fps = float(np.logical_and(pred==1,neq).sum())
    fns = float(np.logical_and(pred==0,neq).sum())
    return fps,fns

if __name__ == '__main__':
    main()